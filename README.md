
# ğŸ›ï¸ Projet ETL - Analyse de DonnÃ©es Transactionnelles (POO - Python)

## ğŸ“Œ Description du Projet

Ce projet a pour objectif de concevoir et dÃ©velopper un pipeline **ETL (Extract, Transform, Load)** orientÃ© objet en Python, basÃ© sur un jeu de donnÃ©es transactionnelles fourni par l'[UCI Machine Learning Repository](https://archive.ics.uci.edu/).  
Le dataset contient des informations de ventes en ligne pour une entreprise britannique spÃ©cialisÃ©e dans la vente de cadeaux.

Le pipeline s'articule autour de trois grandes classes responsables du **nettoyage**, du **traitement des transactions** et de l'**orchestration complÃ¨te du processus ETL**, avec un enregistrement final au format **Parquet**.

---

## ğŸ“ Structure du Projet

```
ETL_Project/
â”‚
â”œâ”€â”€ data/                      # Contient les fichiers source (transactions, fournisseurs, mapping continent)
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_cleaner.py        # Classe DataCleaner
â”‚   â”œâ”€â”€ transaction_processor.py  # Classe TransactionProcessor
â”‚   â”œâ”€â”€ etl_pipeline.py        # Classe ETLPipeline
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ data_cleaner_test.py   # Tests unitaires pour DataCleaner
â”‚   â”œâ”€â”€ transaction_processor_test.py # Tests unitaires pour TransactionProcessor
â”‚
â”œâ”€â”€ output/                    # Contiendra les fichiers gÃ©nÃ©rÃ©s (.parquet)
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## ğŸ§  FonctionnalitÃ©s Principales

### ğŸ”¹ `DataCleaner`
Classe responsable du **nettoyage du DataFrame** :
- Suppression des doublons
- Traitement des valeurs manquantes
- Filtrage des transactions valides (hors annulations)

### ğŸ”¹ `TransactionProcessor`
Classe mÃ©tier dÃ©diÃ©e Ã  lâ€™analyse des transactions :
- Calcul du montant total de chaque transaction
- AgrÃ©gation par pays et par mois
- Analyse des heures de pointe des ventes
- Classement des produits les plus rentables par pays
- Traitement des fournisseurs et leur performance
- Analyse continentale via un mapping externe

### ğŸ”¹ `ETLPipeline`
Classe dâ€™orchestration du projet ETL :
- ExÃ©cution de bout en bout du pipeline (nettoyage â†’ transformation â†’ enrichissement)
- Sauvegarde finale au format **Parquet**

---

## ğŸ§ª Tests Unitaires

Des tests unitaires ont Ã©tÃ© dÃ©veloppÃ©s pour garantir la robustesse du code.  
Chaque classe fonctionnelle dispose de son propre fichier de test :

- `data_cleaner_test.py`
- `transaction_processor_test.py`

Ces tests valident le bon comportement de chaque mÃ©thode, ainsi que la gestion des cas particuliers (valeurs manquantes, formats inattendus, etc.).

---

## ğŸ“ Exigences Techniques

- Python 3.9+
- Pandas
- Pytest
- PyArrow

Installe les dÃ©pendances avec :

```bash
pip install -r requirements.txt
```

---

## ğŸš€ ExÃ©cution du Pipeline

```python
from src.etl_pipeline import ETLPipeline

pipeline = ETLPipeline("data/transactions.csv", "data/suppliers.csv", "data/country_continent_mapping.csv")
pipeline.run_pipeline()
pipeline.save_as_parquet("output/transactions_cleaned.parquet")
```

---

## ğŸ“Š RÃ©sultats Attendues

- Un DataFrame enrichi, prÃªt pour lâ€™analyse exploratoire ou la modÃ©lisation.
- Des insights business : pays les plus dÃ©pensiers, heures de ventes les plus actives, fournisseurs les plus performants.
- Un pipeline modulaire, maintenable et rÃ©utilisable.

---

## ğŸ“š Source de DonnÃ©es

Jeu de donnÃ©es :  
**UCI Machine Learning Repository**  
[Online Retail Data Set](https://archive.ics.uci.edu/ml/datasets/online+retail)

---

## ğŸ‘¨â€ğŸ’» Auteur

DÃ©veloppÃ© par [TonNom](https://github.com/TonNom) dans le cadre dâ€™un projet de data engineering orientÃ© objet.
